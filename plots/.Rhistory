setwd("/home/bthj/ITU/ModernAI/eclipseProjects/MAIG-Autumn-2014_MsPacMan/plots")
geneticAlgorithmRunOutput <- read.table("../data/geneticAlgorithmRunOutput__mutate.05.tab")
generation = geneticAlgorithmRunOutput$V1
averageFitness = geneticAlgorithmRunOutput$V2
plot( generation, averageFitness, type='l' )
setwd("/home/bthj/ITU/ModernAI/eclipseProjects/MAIG-Autumn-2014_MsPacMan/plots")
# geneticAlgorithmRunOutput <- read.table("../data/geneticAlgorithmRunOutput__mutate.05.tab")
geneticAlgorithmRunOutput <- read.table("../data/geneticAlgorithmRunOutput__mutate.125.tab")
generation = geneticAlgorithmRunOutput$V1
averageFitness = geneticAlgorithmRunOutput$V2
plot( generation, averageFitness, type='l' )
plot( generation, averageFitness, type='l', main="Evolution of average fitness", sub="12.5 % mutation probability" )
setwd("/home/bthj/ITU/ModernAI/eclipseProjects/MAIG-Autumn-2014_MsPacMan/plots")
# geneticAlgorithmRunOutput <- read.table("../data/geneticAlgorithmRunOutput__mutate.05.tab")
geneticAlgorithmRunOutput <- read.table("../data/geneticAlgorithmRunOutput__mutate.125.tab")
generation = geneticAlgorithmRunOutput$V1
averageFitness = geneticAlgorithmRunOutput$V2
plot( generation, averageFitness, type='l', main="Evolution of average fitness", sub="12.5 % mutation probability" )
setwd("/home/bthj/ITU/ModernAI/eclipseProjects/MAIG-Autumn-2014_MsPacMan/plots")
geneticAlgorithmRunOutput <- read.table("../data/geneticAlgorithmRunOutput__mutate.05.tab")
# geneticAlgorithmRunOutput <- read.table("../data/geneticAlgorithmRunOutput__mutate.125.tab")
generation = geneticAlgorithmRunOutput$V1
averageFitness = geneticAlgorithmRunOutput$V2
plot( generation, averageFitness, type='l', main="Evolution of average fitness", sub="5 % mutation probability" )
setwd("/home/bthj/ITU/ModernAI/eclipseProjects/MAIG-Autumn-2014_MsPacMan/plots")
neuralNetworkTrainingOutput <- read.table("../data/feedforwardBackpropagationTraining__hiddenNeuronsLessThanTwiceInputSize.tab")
epoch = neuralNetworkTrainingOutput$V1
errorRate = neuralNetworkTrainingOutput$V2
learningRate = neuralNetworkTrainingOutput$V3
plot( epoch, errorRate, learningRate, type='l', main="Evolution of average fitness", sub="5 % mutation probability" )
setwd("/home/bthj/ITU/ModernAI/eclipseProjects/MAIG-Autumn-2014_MsPacMan/plots")
neuralNetworkTrainingOutput <- read.table("../data/feedforwardBackpropagationTraining__hiddenNeuronsLessThanTwiceInputSize.tab")
epoch = neuralNetworkTrainingOutput$V1
errorRate = neuralNetworkTrainingOutput$V2
learningRate = neuralNetworkTrainingOutput$V3
plot( epoch, errorRate,  type='l', main="Evolution of average fitness", sub="5 % mutation probability" )
setwd("/home/bthj/ITU/ModernAI/eclipseProjects/MAIG-Autumn-2014_MsPacMan/plots")
neuralNetworkTrainingOutput <- read.table("../data/feedforwardBackpropagationTraining__hiddenNeuronsLessThanTwiceInputSize.tab")
epoch = neuralNetworkTrainingOutput$V1
errorRate = neuralNetworkTrainingOutput$V2
learningRate = neuralNetworkTrainingOutput$V3
plot( epoch, errorRate, type='l', main="Evolution of average fitness", sub="5 % mutation probability" )
lines( epoch, learningRate, col="green")
setwd("/home/bthj/ITU/ModernAI/eclipseProjects/MAIG-Autumn-2014_MsPacMan/plots")
neuralNetworkTrainingOutput <- read.table("../data/feedforwardBackpropagationTraining__hiddenNeuronsLessThanTwiceInputSize.tab")
epoch = neuralNetworkTrainingOutput$V1
errorRate = neuralNetworkTrainingOutput$V2
learningRate = neuralNetworkTrainingOutput$V3
plot( epoch, errorRate, type='l', main="Evolution of average fitness", sub="5 % mutation probability" )
lines( epoch, learningRate, col="green")
setwd("/home/bthj/ITU/ModernAI/eclipseProjects/MAIG-Autumn-2014_MsPacMan/plots")
neuralNetworkTrainingOutput <- read.table("../data/feedforwardBackpropagationTraining__hiddenNeuronsLessThanTwiceInputSize.tab")
epoch = neuralNetworkTrainingOutput$V1
errorRate = neuralNetworkTrainingOutput$V2
learningRate = neuralNetworkTrainingOutput$V3
# plot( epoch, errorRate, type='l', main="Evolution of average fitness", sub="5 % mutation probability" )
plot( epoch, errorRate, col="red" )
lines( epoch, learningRate, col="green")
setwd("/home/bthj/ITU/ModernAI/eclipseProjects/MAIG-Autumn-2014_MsPacMan/plots")
neuralNetworkTrainingOutput <- read.table("../data/feedforwardBackpropagationTraining__hiddenNeuronsLessThanTwiceInputSize.tab")
epoch = neuralNetworkTrainingOutput$V1
errorRate = neuralNetworkTrainingOutput$V2
learningRate = neuralNetworkTrainingOutput$V3
# plot( epoch, errorRate, type='l', main="Evolution of average fitness", sub="5 % mutation probability" )
plot( epoch, errorRate, type="l", col="red" )
lines( epoch, learningRate, col="green")
setwd("/home/bthj/ITU/ModernAI/eclipseProjects/MAIG-Autumn-2014_MsPacMan/plots")
neuralNetworkTrainingOutput <- read.table("../data/feedforwardBackpropagationTraining__hiddenNeuronsLessThanTwiceInputSize.tab")
epoch = neuralNetworkTrainingOutput$V1
errorRate = neuralNetworkTrainingOutput$V2
learningRate = neuralNetworkTrainingOutput$V3
# plot( epoch, errorRate, type='l', main="Evolution of average fitness", sub="5 % mutation probability" )
# plot( epoch, errorRate, type="l", col="red" )
# lines( epoch, learningRate, col="green")
plot( epoch, learningRate, type="l", col="red" )
setwd("/home/bthj/ITU/ModernAI/eclipseProjects/MAIG-Autumn-2014_MsPacMan/plots")
neuralNetworkTrainingOutput <- read.table("../data/feedforwardBackpropagationTraining__hiddenNeuronsLessThanTwiceInputSize.tab")
epoch = neuralNetworkTrainingOutput$V1
errorRate = neuralNetworkTrainingOutput$V2
learningRate = neuralNetworkTrainingOutput$V3
# plot( epoch, errorRate, type='l', main="Evolution of average fitness", sub="5 % mutation probability" )
plot( epoch, errorRate, type="l", col="red" )
lines( epoch, learningRate, col="green")
#plot( epoch, learningRate, type="l", col="red" )
setwd("/home/bthj/ITU/ModernAI/eclipseProjects/MAIG-Autumn-2014_MsPacMan/plots")
neuralNetworkTrainingOutput <- read.table("../data/feedforwardBackpropagationTraining__hiddenNeuronsLessThanTwiceInputSize.tab")
epoch = neuralNetworkTrainingOutput$V1
errorRate = neuralNetworkTrainingOutput$V2
learningRate = neuralNetworkTrainingOutput$V3
plot( epoch, errorRate, type='l', main="ANN error rate during training epochs", sub="5 % mutation probability" )
# plot( epoch, errorRate, type="l", col="red" )
# lines( epoch, learningRate, col="green")
#plot( epoch, learningRate, type="l", col="red" )
setwd("/home/bthj/ITU/ModernAI/eclipseProjects/MAIG-Autumn-2014_MsPacMan/plots")
neuralNetworkTrainingOutput <- read.table("../data/feedforwardBackpropagationTraining__hiddenNeuronsLessThanTwiceInputSize.tab")
epoch = neuralNetworkTrainingOutput$V1
errorRate = neuralNetworkTrainingOutput$V2
learningRate = neuralNetworkTrainingOutput$V3
plot( epoch, errorRate, type='l', main="ANN error rate during training epochs", sub="0.1 fixed learning rate, hidden neurons = input * 1.7" )
# plot( epoch, errorRate, type="l", col="red" )
# lines( epoch, learningRate, col="green")
#plot( epoch, learningRate, type="l", col="red" )
setwd("/home/bthj/ITU/ModernAI/eclipseProjects/MAIG-Autumn-2014_MsPacMan/plots")
neuralNetworkTrainingOutput <- read.table("../data/feedforwardBackpropagationTraining__hiddenNeuronsLessThanTwiceInputSize.tab")
epoch = neuralNetworkTrainingOutput$V1
errorRate = neuralNetworkTrainingOutput$V2
learningRate = neuralNetworkTrainingOutput$V3
plot( epoch, errorRate, type='l', main="ANN error rate during training epochs", sub="0.1 fixed learning rate, hidden neurons = input x 1.7" )
# plot( epoch, errorRate, type="l", col="red" )
# lines( epoch, learningRate, col="green")
#plot( epoch, learningRate, type="l", col="red" )
setwd("/home/bthj/ITU/ModernAI/eclipseProjects/MAIG-Autumn-2014_MsPacMan/plots")
neuralNetworkTrainingOutput <- read.table("../data/feedforwardBackpropagationTraining__hiddenNeuronsLessThanTwiceInputSize.tab")
epoch = neuralNetworkTrainingOutput$V1
errorRate = neuralNetworkTrainingOutput$V2
learningRate = neuralNetworkTrainingOutput$V3
plot( epoch, errorRate, type='l', main="ANN error rate during training epochs", sub="0.1 fixed learning rate, hidden neurons = input * 1.7" )
# plot( epoch, errorRate, type="l", col="red" )
# lines( epoch, learningRate, col="green")
#plot( epoch, learningRate, type="l", col="red" )
setwd("/home/bthj/ITU/ModernAI/eclipseProjects/MAIG-Autumn-2014_MsPacMan/plots")
neuralNetworkTrainingOutput <- read.table("../data/feedforwardBackpropagationTraining__hiddenNeuronsLessThanTwiceInputSize.tab")
epoch = neuralNetworkTrainingOutput$V1
errorRate = neuralNetworkTrainingOutput$V2
learningRate = neuralNetworkTrainingOutput$V3
plot( epoch, errorRate, type='l', main="ANN error rate during training epochs", sub="0.1 fixed learning rate, hidden neurons = input neurons * 1.7" )
# plot( epoch, errorRate, type="l", col="red" )
# lines( epoch, learningRate, col="green")
#plot( epoch, learningRate, type="l", col="red" )
setwd("/home/bthj/ITU/ModernAI/eclipseProjects/MAIG-Autumn-2014_MsPacMan/plots")
neuralNetworkTrainingOutput <- read.table("../data/feedforwardBackpropagationTraining__hiddenNeuronsLessThanTwiceInputSize.tab")
epoch = neuralNetworkTrainingOutput$V1
errorRate = neuralNetworkTrainingOutput$V2
learningRate = neuralNetworkTrainingOutput$V3
plot( epoch, errorRate, type='l', main="ANN error rate during training epochs", sub="Input set 1, 0.1 fixed learning rate, hidden neurons = input neurons * 1.7" )
# plot( epoch, errorRate, type="l", col="red" )
# lines( epoch, learningRate, col="green")
#plot( epoch, learningRate, type="l", col="red" )
setwd("/home/bthj/ITU/ModernAI/eclipseProjects/MAIG-Autumn-2014_MsPacMan/plots")
neuralNetworkTrainingOutput <- read.table("../data/feedforwardBackpropagationTraining__hiddenNeuronsLessThanTwiceInputSize.tab")
epoch = neuralNetworkTrainingOutput$V1
errorRate = neuralNetworkTrainingOutput$V2
learningRate = neuralNetworkTrainingOutput$V3
plot( epoch, errorRate, type='l', main="ANN error rate during training epochs", sub="Input set 1.  Fixed learning rate at 0.1.  Hidden neurons = input neurons * 1.7" )
# plot( epoch, errorRate, type="l", col="red" )
# lines( epoch, learningRate, col="green")
#plot( epoch, learningRate, type="l", col="red" )
setwd("/home/bthj/ITU/ModernAI/eclipseProjects/MAIG-Autumn-2014_MsPacMan/plots")
neuralNetworkTrainingOutput <- read.table("../data/feedforwardBackpropagationTraining__hiddenNeuronsLessThanTwiceInputSize.tab")
epoch = neuralNetworkTrainingOutput$V1
errorRate = neuralNetworkTrainingOutput$V2
learningRate = neuralNetworkTrainingOutput$V3
plot( epoch, errorRate, type='l', main="ANN error rate during training epochs", sub="Input set 1.  Fixed learning rate at 0.1.  Hidden neurons = input neurons * 1.7" )
# plot( epoch, errorRate, type="l", col="red" )
# lines( epoch, learningRate, col="green")
#plot( epoch, learningRate, type="l", col="red" )
setwd("/home/bthj/ITU/ModernAI/eclipseProjects/MAIG-Autumn-2014_MsPacMan/plots")
# neuralNetworkTrainingOutput <- read.table("../data/feedforwardBackpropagationTraining__hiddenNeuronsLessThanTwiceInputSize.tab")
neuralNetworkTrainingOutput <- read.table("../data/feedforwardBackpropagationTraining__learningRateDownEvery100thEpoch.tab")
epoch = neuralNetworkTrainingOutput$V1
errorRate = neuralNetworkTrainingOutput$V2
learningRate = neuralNetworkTrainingOutput$V3
# plot( epoch, errorRate, type='l', main="ANN error rate during training epochs", sub="Input set 1.  Fixed learning rate at 0.1.  Hidden neurons = input neurons * 1.7" )
plot( epoch, errorRate, type='l', main="ANN error rate during training epochs", sub="Input set 1.  Learning rate 1/t (every 100th epoch).  Hidden neurons = input neurons * (2/3) + output neurons." )
# plot( epoch, errorRate, type="l", col="red" )
# lines( epoch, learningRate, col="green")
#plot( epoch, learningRate, type="l", col="red" )
setwd("/home/bthj/ITU/ModernAI/eclipseProjects/MAIG-Autumn-2014_MsPacMan/plots")
# neuralNetworkTrainingOutput <- read.table("../data/feedforwardBackpropagationTraining__hiddenNeuronsLessThanTwiceInputSize.tab")
neuralNetworkTrainingOutput <- read.table("../data/feedforwardBackpropagationTraining__learningRateFixedAt0dot1.tab")
# neuralNetworkTrainingOutput <- read.table("../data/feedforwardBackpropagationTraining__learningRateDownEvery100thEpoch.tab")
epoch = neuralNetworkTrainingOutput$V1
errorRate = neuralNetworkTrainingOutput$V2
learningRate = neuralNetworkTrainingOutput$V3
# plot( epoch, errorRate, type='l', main="ANN error rate during training epochs", sub="Input set 1.  Fixed learning rate at 0.1.  Hidden neurons = input neurons * 1.7" )
plot( epoch, errorRate, type='l', main="ANN error rate during training epochs", sub="Input set 1.  Fixed learning rate at 0.1.  Hidden neurons = input neurons * (2/3) + output neurons" )
# plot( epoch, errorRate, type='l', main="ANN error rate during training epochs", sub="Input set 1.  Learning rate 1/t (every 100th epoch).  Hidden neurons = input neurons * (2/3) + output neurons" )
# plot( epoch, errorRate, type="l", col="red" )
# lines( epoch, learningRate, col="green")
#plot( epoch, learningRate, type="l", col="red" )
setwd("/home/bthj/ITU/ModernAI/eclipseProjects/MAIG-Autumn-2014_MsPacMan/plots")
# neuralNetworkTrainingOutput <- read.table("../data/feedforwardBackpropagationTraining__hiddenNeuronsLessThanTwiceInputSize.tab")
# neuralNetworkTrainingOutput <- read.table("../data/feedforwardBackpropagationTraining__learningRateFixedAt0dot1.tab")
# neuralNetworkTrainingOutput <- read.table("../data/feedforwardBackpropagationTraining__learningRateDownEvery100thEpoch.tab")
neuralNetworkTrainingOutput <- read.table("../data/feedforwardBackpropagationTraining__learningRateFixedAt0dot1__alternativeInputSet.tab")
epoch = neuralNetworkTrainingOutput$V1
errorRate = neuralNetworkTrainingOutput$V2
learningRate = neuralNetworkTrainingOutput$V3
# plot( epoch, errorRate, type='l', main="ANN error rate during training epochs", sub="Input set 1.  Fixed learning rate at 0.1.  Hidden neurons = input neurons * 1.7" )
# plot( epoch, errorRate, type='l', main="ANN error rate during training epochs", sub="Input set 1.  Fixed learning rate at 0.1.  Hidden neurons = input neurons * (2/3) + output neurons" )
# plot( epoch, errorRate, type='l', main="ANN error rate during training epochs", sub="Input set 1.  Learning rate 1/t (every 100th epoch).  Hidden neurons = input neurons * (2/3) + output neurons" )
plot( epoch, errorRate, type='l', main="ANN error rate during training epochs", sub="Input set 2.  Fixed learning rate at 0.1.  Hidden neurons = input neurons * (2/3) + output neurons" )
# plot( epoch, errorRate, type="l", col="red" )
# lines( epoch, learningRate, col="green")
#plot( epoch, learningRate, type="l", col="red" )
setwd("/home/bthj/ITU/ModernAI/eclipseProjects/MAIG-Autumn-2014_MsPacMan/plots")
# neuralNetworkTrainingOutput <- read.table("../data/feedforwardBackpropagationTraining__hiddenNeuronsLessThanTwiceInputSize.tab")
# neuralNetworkTrainingOutput <- read.table("../data/feedforwardBackpropagationTraining__learningRateFixedAt0dot1.tab")
# neuralNetworkTrainingOutput <- read.table("../data/feedforwardBackpropagationTraining__learningRateDownEvery100thEpoch.tab")
# neuralNetworkTrainingOutput <- read.table("../data/feedforwardBackpropagationTraining__learningRateFixedAt0dot1__alternativeInputSet.tab")
neuralNetworkTrainingOutput <- read.table("../data/feedforwardBackpropagationTraining__learningRateDownEvery100thEpoch__alternativeInputSet.tab")
epoch = neuralNetworkTrainingOutput$V1
errorRate = neuralNetworkTrainingOutput$V2
learningRate = neuralNetworkTrainingOutput$V3
# plot( epoch, errorRate, type='l', main="ANN error rate during training epochs", sub="Input set 1.  Fixed learning rate at 0.1.  Hidden neurons = input neurons * 1.7" )
# plot( epoch, errorRate, type='l', main="ANN error rate during training epochs", sub="Input set 1.  Fixed learning rate at 0.1.  Hidden neurons = input neurons * (2/3) + output neurons" )
# plot( epoch, errorRate, type='l', main="ANN error rate during training epochs", sub="Input set 1.  Learning rate 1/t (every 100th epoch).  Hidden neurons = input neurons * (2/3) + output neurons" )
# plot( epoch, errorRate, type='l', main="ANN error rate during training epochs", sub="Input set 2.  Fixed learning rate at 0.1.  Hidden neurons = input neurons * (2/3) + output neurons" )
plot( epoch, errorRate, type='l', main="ANN error rate during training epochs", sub="Input set 2.  Learning rate 1/t (every 100th epoch).  Hidden neurons = input neurons * (2/3) + output neurons" )
# plot( epoch, errorRate, type="l", col="red" )
# lines( epoch, learningRate, col="green")
#plot( epoch, learningRate, type="l", col="red" )
setwd("/home/bthj/ITU/ModernAI/eclipseProjects/MAIG-Autumn-2014_MsPacMan/plots")
# neuralNetworkTrainingOutput <- read.table("../data/feedforwardBackpropagationTraining__hiddenNeuronsLessThanTwiceInputSize.tab")
# neuralNetworkTrainingOutput <- read.table("../data/feedforwardBackpropagationTraining__learningRateFixedAt0dot1.tab")
# neuralNetworkTrainingOutput <- read.table("../data/feedforwardBackpropagationTraining__learningRateDownEvery100thEpoch.tab")
# neuralNetworkTrainingOutput <- read.table("../data/feedforwardBackpropagationTraining__learningRateFixedAt0dot1__alternativeInputSet.tab")
# neuralNetworkTrainingOutput <- read.table("../data/feedforwardBackpropagationTraining__learningRateDownEvery100thEpoch__alternativeInputSet.tab")
neuralNetworkTrainingOutput <- read.table("../data/feedforwardBackpropagationTraining__learningRateDownEvery100thEpoch__alternativeInputSet__hiddenNeuronsLessThanTwiceInputSize.tab")
epoch = neuralNetworkTrainingOutput$V1
errorRate = neuralNetworkTrainingOutput$V2
learningRate = neuralNetworkTrainingOutput$V3
# plot( epoch, errorRate, type='l', main="ANN error rate during training epochs", sub="Input set 1.  Fixed learning rate at 0.1.  Hidden neurons = input neurons * 1.7" )
# plot( epoch, errorRate, type='l', main="ANN error rate during training epochs", sub="Input set 1.  Fixed learning rate at 0.1.  Hidden neurons = input neurons * (2/3) + output neurons" )
# plot( epoch, errorRate, type='l', main="ANN error rate during training epochs", sub="Input set 1.  Learning rate 1/t (every 100th epoch).  Hidden neurons = input neurons * (2/3) + output neurons" )
# plot( epoch, errorRate, type='l', main="ANN error rate during training epochs", sub="Input set 2.  Fixed learning rate at 0.1.  Hidden neurons = input neurons * (2/3) + output neurons" )
# plot( epoch, errorRate, type='l', main="ANN error rate during training epochs", sub="Input set 2.  Learning rate 1/t (every 100th epoch).  Hidden neurons = input neurons * (2/3) + output neurons" )
plot( epoch, errorRate, type='l', main="ANN error rate during training epochs", sub="Input set 2.  Learning rate 1/t (every 100th epoch).  Hidden neurons = input neurons * 1.7" )
# plot( epoch, errorRate, type="l", col="red" )
# lines( epoch, learningRate, col="green")
#plot( epoch, learningRate, type="l", col="red" )
setwd("/home/bthj/ITU/ModernAI/eclipseProjects/MAIG-Autumn-2014_MsPacMan/plots")
# neuralNetworkTrainingOutput <- read.table("../data/feedforwardBackpropagationTraining__hiddenNeuronsLessThanTwiceInputSize.tab")
# neuralNetworkTrainingOutput <- read.table("../data/feedforwardBackpropagationTraining__learningRateFixedAt0dot1.tab")
# neuralNetworkTrainingOutput <- read.table("../data/feedforwardBackpropagationTraining__learningRateDownEvery100thEpoch.tab")
# neuralNetworkTrainingOutput <- read.table("../data/feedforwardBackpropagationTraining__learningRateFixedAt0dot1__alternativeInputSet.tab")
# neuralNetworkTrainingOutput <- read.table("../data/feedforwardBackpropagationTraining__learningRateDownEvery100thEpoch__alternativeInputSet.tab")
# neuralNetworkTrainingOutput <- read.table("../data/feedforwardBackpropagationTraining__learningRateDownEvery100thEpoch__alternativeInputSet__hiddenNeuronsLessThanTwiceInputSize.tab")
neuralNetworkTrainingOutput <- read.table("../data/feedforwardBackpropagationTraining__hiddenNeuronsLessThanTwiceInputSize__alternativeInputSet.tab")
epoch = neuralNetworkTrainingOutput$V1
errorRate = neuralNetworkTrainingOutput$V2
learningRate = neuralNetworkTrainingOutput$V3
# plot( epoch, errorRate, type='l', main="ANN error rate during training epochs", sub="Input set 1.  Fixed learning rate at 0.1.  Hidden neurons = input neurons * 1.7" )
# plot( epoch, errorRate, type='l', main="ANN error rate during training epochs", sub="Input set 1.  Fixed learning rate at 0.1.  Hidden neurons = input neurons * (2/3) + output neurons" )
# plot( epoch, errorRate, type='l', main="ANN error rate during training epochs", sub="Input set 1.  Learning rate 1/t (every 100th epoch).  Hidden neurons = input neurons * (2/3) + output neurons" )
# plot( epoch, errorRate, type='l', main="ANN error rate during training epochs", sub="Input set 2.  Fixed learning rate at 0.1.  Hidden neurons = input neurons * (2/3) + output neurons" )
# plot( epoch, errorRate, type='l', main="ANN error rate during training epochs", sub="Input set 2.  Learning rate 1/t (every 100th epoch).  Hidden neurons = input neurons * (2/3) + output neurons" )
# plot( epoch, errorRate, type='l', main="ANN error rate during training epochs", sub="Input set 2.  Learning rate 1/t (every 100th epoch).  Hidden neurons = input neurons * 1.7" )
plot( epoch, errorRate, type='l', main="ANN error rate during training epochs", sub="Input set 2.  Fixed learning rate at 0.1.  Hidden neurons = input neurons * 1.7" )
# plot( epoch, errorRate, type="l", col="red" )
# lines( epoch, learningRate, col="green")
#plot( epoch, learningRate, type="l", col="red" )
setwd("/home/bthj/ITU/ModernAI/eclipseProjects/MAIG-Autumn-2014_MsPacMan/plots")
MCTSscore <- read.table("../data/MCTSforPacMan__DefaultPolicy__iterationLimitTrials.tab")
playoutIterationLimit = MCTSscore$V1
score = MCTSscore$V2
plot( playoutIterationLimit, score, type='l', main="MCTS PacMan score VS simulation iteration limits", sub="PacMan performs random available moves during playouts" )
setwd("/home/bthj/ITU/ModernAI/eclipseProjects/MAIG-Autumn-2014_MsPacMan/plots")
MCTSscore <- read.table("../data/MCTSforPacMan__DefaultPolicy__iterationLimitTrials.tab")
playoutIterationLimit = MCTSscore$V1
score = MCTSscore$V2
plot( playoutIterationLimit, score, type='l', main="MCTS PacMan score VS simulation iteration limits", sub="PacMan performs random available moves during playouts. Zero limit = unlimited" )
setwd("/home/bthj/ITU/ModernAI/eclipseProjects/MAIG-Autumn-2014_MsPacMan/plots")
MCTSscore <- read.table("../data/MCTSforPacMan__DefaultPolicy__iterationLimitTrials.tab")
playoutIterationLimit = MCTSscore$V1
score = MCTSscore$V2
plot( playoutIterationLimit, score, type='l', main="MCTS PacMan score VS simulation iteration limits", sub="PacMan performs random available moves during playouts.  Zero limit = unlimited" )
setwd("/home/bthj/ITU/ModernAI/eclipseProjects/MAIG-Autumn-2014_MsPacMan/plots")
# MCTSscore <- read.table("../data/MCTSforPacMan__DefaultPolicy__iterationLimitTrials.tab")
MCTSscore <- read.table("../data/MCTSforPacMan__GeneticControllerSimulation__iterationLimitTrials.tab")
playoutIterationLimit = MCTSscore$V1
score = MCTSscore$V2
# plot( playoutIterationLimit, score, type='l', main="MCTS PacMan score VS simulation iteration limits", sub="PacMan performs random available moves during playouts.  Zero limit = unlimited" )
plot( playoutIterationLimit, score, type='l', main="MCTS PacMan score VS simulation iteration limits", sub="PacMan uses a genetically evolved controller for moves during playouts.  Zero limit = unlimited" )
